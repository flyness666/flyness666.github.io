<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>爬虫笔记 - CZH&#039;s BLOG</title><meta description="requests基础爬取静态网页内容 反爬机制： User-Agent  发送请求时验证 User-Agent ，会阻止非浏览器的请求 破解方法：在 headers 中使用浏览器的 User-Agent 进行伪装    123456import requestsurl &amp;#x3D; &amp;#39;https:&amp;#x2F;&amp;#x2F;www.sogou.com&amp;#x2F;&amp;#39;response &amp;#x3D; requests.get(url &amp;#x3D; url)page_"><meta property="og:type" content="blog"><meta property="og:title" content="爬虫笔记"><meta property="og:url" content="http://yoursite.com/2020/04/26/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"><meta property="og:site_name" content="CZH&#039;s BLOG"><meta property="og:description" content="requests基础爬取静态网页内容 反爬机制： User-Agent  发送请求时验证 User-Agent ，会阻止非浏览器的请求 破解方法：在 headers 中使用浏览器的 User-Agent 进行伪装    123456import requestsurl &amp;#x3D; &amp;#39;https:&amp;#x2F;&amp;#x2F;www.sogou.com&amp;#x2F;&amp;#39;response &amp;#x3D; requests.get(url &amp;#x3D; url)page_"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/flyness666/pictures/main/2020-04-26_douban.png"><meta property="article:published_time" content="2020-04-26T14:36:41.000Z"><meta property="article:modified_time" content="2021-03-06T15:26:54.641Z"><meta property="article:author" content="CZH"><meta property="article:tag" content="笔记"><meta property="article:tag" content="爬虫"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/flyness666/pictures/main/2020-04-26_douban.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2020/04/26/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"},"headline":"CZH's BLOG","image":["https://raw.githubusercontent.com/flyness666/pictures/main/2020-04-26_douban.png"],"datePublished":"2020-04-26T14:36:41.000Z","dateModified":"2021-03-06T15:26:54.641Z","author":{"@type":"Person","name":"CZH"},"description":"requests基础爬取静态网页内容 反爬机制： User-Agent  发送请求时验证 User-Agent ，会阻止非浏览器的请求 破解方法：在 headers 中使用浏览器的 User-Agent 进行伪装    123456import requestsurl &#x3D; &#39;https:&#x2F;&#x2F;www.sogou.com&#x2F;&#39;response &#x3D; requests.get(url &#x3D; url)page_"}</script><link rel="canonical" href="http://yoursite.com/2020/04/26/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=https://fonts.googleapis.com/css?family=Roboto:400"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="CZH&#039;s BLOG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub地址" href="https://github.com/flyness666"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-26T14:36:41.000Z" title="2020-04-26T14:36:41.000Z">2020-04-26</time><span class="level-item"><a class="link-muted" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span><span class="level-item">1 小时 读完 (大约 7075 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">爬虫笔记</h1><div class="content"><h1 id="requests基础"><a href="#requests基础" class="headerlink" title="requests基础"></a><strong>requests基础</strong></h1><h2 id="爬取静态网页内容"><a href="#爬取静态网页内容" class="headerlink" title="爬取静态网页内容"></a><strong>爬取静态网页内容</strong></h2><ul>
<li>反爬机制： <code>User-Agent</code> <ul>
<li>发送请求时验证 <code>User-Agent</code> ，会阻止非浏览器的请求</li>
<li>破解方法：在 <code>headers</code> 中使用浏览器的 <code>User-Agent</code> 进行伪装</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'https://www.sogou.com/'</span></span><br><span class="line">response = requests.get(url = url)</span><br><span class="line">page_text = response.text</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./sougou.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">keyword = input(<span class="string">'enter a key word:'</span>)</span><br><span class="line">headers = &#123;  <span class="comment"># User-Agent伪装</span></span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">params = &#123;  <span class="comment"># 请求参数</span></span><br><span class="line">    <span class="string">'query'</span>:keyword</span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://www.sogou.com/web'</span></span><br><span class="line">response = requests.get(url=url, params=params, headers=headers)</span><br><span class="line">response.encoding = <span class="string">'utf-8'</span></span><br><span class="line">page_text = response.text</span><br><span class="line">filename = keyword + <span class="string">'.html'</span></span><br><span class="line"><span class="keyword">with</span> open(filename, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text)</span><br><span class="line">print(filename, <span class="string">'爬取完毕！'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="爬取动态网页内容"><a href="#爬取动态网页内容" class="headerlink" title="爬取动态网页内容"></a><strong>爬取动态网页内容</strong></h2><ul>
<li>反爬机制：动态数据<ul>
<li>网页内数据动态生成，不会在打开网页时就生成</li>
<li>使用静态网页爬虫方法只能获取网页静态元素，不能获取具体数据</li>
<li>破解方法：基于抓包工具进行全局搜索，寻找发送该数据的网页和请求参数</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://movie.douban.com/explore#!type=movie&amp;tag=%E5%8A%A8%E4%BD%9C&amp;sort=recommend&amp;page_limit=20&amp;page_start=0'</span></span><br><span class="line">response = requests.get(url=url,headers=headers)</span><br><span class="line">page_text = response.text</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./douban.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text)</span><br></pre></td></tr></table></figure>
<ul>
<li>此方法不能获取数据，生成的网页如下<br><img src="https://raw.githubusercontent.com/flyness666/pictures/main/2020-04-26_douban.png" alt="douban"></li>
<li>原因：豆瓣网页为动态数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://movie.douban.com/j/chart/top_list'</span></span><br><span class="line">params = &#123;  <span class="comment"># 请求参数</span></span><br><span class="line">    <span class="string">'type_name'</span>:<span class="string">'动作'</span>,</span><br><span class="line">    <span class="string">'type'</span>:<span class="string">'5'</span>,</span><br><span class="line">    <span class="string">'interval_id'</span>:<span class="string">'100:90'</span>,</span><br><span class="line">    <span class="string">'action'</span>:<span class="string">''</span>,</span><br><span class="line">    <span class="string">'limit'</span>:<span class="string">'20'</span>,</span><br><span class="line">    <span class="string">'start'</span>:<span class="string">'0'</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url=url, params=params, headers=headers)</span><br><span class="line">page_text = response.json()</span><br><span class="line"><span class="keyword">for</span> movie <span class="keyword">in</span> page_text:</span><br><span class="line">    name = movie[<span class="string">'title'</span>]</span><br><span class="line">    score = movie[<span class="string">'score'</span>]</span><br><span class="line">    print(name,score)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">福尔摩斯二世 <span class="number">9.5</span></span><br><span class="line">这个杀手不太冷 <span class="number">9.4</span></span><br><span class="line">蝙蝠侠：黑暗骑士 <span class="number">9.2</span></span><br><span class="line">指环王<span class="number">3</span>：王者无敌 <span class="number">9.2</span></span><br><span class="line">七武士 <span class="number">9.2</span></span><br><span class="line">指环王<span class="number">2</span>：双塔奇兵 <span class="number">9.1</span></span><br><span class="line">将军号 <span class="number">9.1</span></span><br><span class="line">搏击俱乐部 <span class="number">9.0</span></span><br><span class="line">指环王<span class="number">1</span>：魔戒再现 <span class="number">9.0</span></span><br><span class="line">黑客帝国 <span class="number">9.0</span></span><br><span class="line">攻壳机动队 <span class="number">9.0</span></span><br><span class="line">赛文奥特曼 我是地球人 <span class="number">9.0</span></span><br><span class="line">V字仇杀队 <span class="number">8.9</span></span><br><span class="line">勇敢的心 <span class="number">8.9</span></span><br><span class="line">乱 <span class="number">8.9</span></span><br><span class="line">用心棒 <span class="number">8.9</span></span><br><span class="line">让子弹飞 <span class="number">8.8</span></span><br><span class="line">蝙蝠侠：黑暗骑士崛起 <span class="number">8.8</span></span><br><span class="line">杀人回忆 <span class="number">8.8</span></span><br><span class="line">谍影重重<span class="number">3</span> <span class="number">8.8</span></span><br></pre></td></tr></table></figure>
<ul>
<li>基于抓包工具进行全局搜索不一定可以每次都能定位到动态加载数据对应的数据包</li>
<li>原因：有些动态数据的数据是经过加密的密文数据</li>
</ul>
<h2 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a><strong>实验代码</strong></h2><ul>
<li>爬取药监总局中的企业详细数据</li>
<li>URL：<a href="http://125.35.6.84:81/xk/">http://125.35.6.84:81/xk/</a></li>
<li>需求：<ul>
<li>将首页中每一家企业的详情数据进行爬取</li>
<li>将前5页企业的数据爬取即可</li>
</ul>
</li>
<li>难点：<ul>
<li>用不到数据解析</li>
<li>所有的数据都是动态加载出来</li>
</ul>
</li>
<li>提示：可以先试着将一家企业的详情页的数据爬取出来</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬取单个企业详情信息</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'http://125.35.6.84:81/xk/itownet/portalAction.do?method=getXkzsById'</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'id'</span>:<span class="string">'057ca436be1d4b34a2ce8033963fd29b'</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.post(url=url, headers=headers, data=data)</span><br><span class="line">page_text = response.json()</span><br><span class="line">epsName = page_text[<span class="string">'epsName'</span>]</span><br><span class="line">epsAddress = page_text[<span class="string">'epsAddress'</span>]</span><br><span class="line">legalPerson = page_text[<span class="string">'legalPerson'</span>]</span><br><span class="line">print(epsName,epsAddress,legalPerson)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬取前5页企业的数据详情页面信息</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'http://125.35.6.84:81/xk/itownet/portalAction.do?method=getXkzsList'</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">'page'</span>:str(page),</span><br><span class="line">        <span class="string">'pageSize'</span>:<span class="string">'15'</span>,</span><br><span class="line">        <span class="string">'productName'</span>:<span class="string">''</span>,</span><br><span class="line">        <span class="string">'conditionType'</span>:<span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'applyname'</span>:<span class="string">''</span>,</span><br><span class="line">        <span class="string">'applysn'</span>:<span class="string">''</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(url=url, headers=headers, data=data)</span><br><span class="line">    page_text = response.json()</span><br><span class="line">    <span class="keyword">for</span> dic <span class="keyword">in</span> page_text[<span class="string">'list'</span>]:</span><br><span class="line">        EPS_NAME = dic[<span class="string">'EPS_NAME'</span>]</span><br><span class="line">        ID = dic[<span class="string">'ID'</span>]</span><br><span class="line">        PRODUCT_SN = dic[<span class="string">'PRODUCT_SN'</span>]</span><br><span class="line">        print(EPS_NAME, ID, PRODUCT_SN)</span><br></pre></td></tr></table></figure>
<h1 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a><strong>数据解析</strong></h1><h2 id="数据解析-1"><a href="#数据解析-1" class="headerlink" title="数据解析"></a><strong>数据解析</strong></h2><ul>
<li>数据解析的作用：<ul>
<li>用来实现聚焦爬虫</li>
</ul>
</li>
<li>网页中显示的数据的存储位置<ul>
<li>存储在 <code>html</code> 的标签或标签的属性中</li>
</ul>
</li>
<li>数据解析的通用原理是什么：<ul>
<li>指定标签的定位</li>
<li>取出标签中存储的数据或者标签属性中的数据</li>
</ul>
</li>
</ul>
<h2 id="爬取图片数据"><a href="#爬取图片数据" class="headerlink" title="爬取图片数据"></a><strong>爬取图片数据</strong></h2><ul>
<li>如何爬取图片数据？<ul>
<li>方式1：基于 <code>requests</code></li>
<li>方式2：基于 <code>urllib</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方式一</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">img_url = <span class="string">'https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1586689315802&amp;di=1829a30a79d82c360234f3b741aa0454&amp;imgtype=0&amp;src=http%3A%2F%2F09imgmini.eastday.com%2Fmobile%2F20180822%2F20180822110947_ffe3aa1a54091501ccaa357fa0e2669a_4.jpeg'</span></span><br><span class="line">response = requests.get(url=img_url, headers=headers)</span><br><span class="line">img_data = response.content</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'1.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(img_data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方式二</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">img_url = <span class="string">'https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1586689315802&amp;di=1829a30a79d82c360234f3b741aa0454&amp;imgtype=0&amp;src=http%3A%2F%2F09imgmini.eastday.com%2Fmobile%2F20180822%2F20180822110947_ffe3aa1a54091501ccaa357fa0e2669a_4.jpeg'</span></span><br><span class="line"><span class="comment">#直接对url发起请求且进行持久化存储</span></span><br><span class="line">urllib.request.urlretrieve(img_url, <span class="string">'./2.jpg'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>urllib</code> 模块作用和 <code>requests</code> 模块一样，都是基于网络请求的模块<ul>
<li>区别： <code>urllib</code> 无法进行 <code>UA</code> 伪装，而 <code>requests</code> 可以</li>
</ul>
</li>
<li>分析浏览器开发者工具中 <code>Elements</code> 和 <code>network</code> 两个选项的页面源码的不同之处<ul>
<li><code>Elements</code> 中的源码为当前页面所有数据加载完毕后对应的完整的页面源码数据（包括动态加载数据）</li>
<li><code>network</code> 显示的页面源码为某一请求的数据包（不包括动态加载数据）</li>
<li>如果当前网站没有动态加载数据就可以直接使用 <code>Elements</code> 对页面布局进行分析，否则只可以使用 <code>network</code> 对页面数据进行分析</li>
</ul>
</li>
</ul>
<h2 id="正则数据解析"><a href="#正则数据解析" class="headerlink" title="正则数据解析"></a><strong>正则数据解析</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">dirname = <span class="string">'imglibs'</span> <span class="comment"># 创建存储图片的文件夹</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dirname):</span><br><span class="line">    os.mkdir(dirname)</span><br><span class="line"><span class="comment">#1.捕获当前页面的页面源码数据</span></span><br><span class="line">url = <span class="string">'http://www.521609.com/daxuexiaohua/'</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers).text</span><br><span class="line"><span class="comment">#2.从当前获取的页码数据中解析出图片地址</span></span><br><span class="line">ex = <span class="string">'&lt;li&gt;.*?&lt;img src="(.*?)".*?&lt;/li&gt;'</span>  <span class="comment"># 正则表达式解析数据</span></span><br><span class="line">img_src_list = re.findall(ex, page_text,re.S)   <span class="comment"># 正则表达式获取数据</span></span><br><span class="line"><span class="keyword">for</span> src <span class="keyword">in</span> img_src_list:</span><br><span class="line">    src = <span class="string">'http://www.521609.com'</span>+src</span><br><span class="line">    img_path = dirname + <span class="string">'/'</span> + src.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">    urllib.request.urlretrieve(src, img_path)</span><br><span class="line">    print(img_path,<span class="string">'下载成功'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="bs4解析数据"><a href="#bs4解析数据" class="headerlink" title="bs4解析数据"></a><strong>bs4解析数据</strong></h2><ul>
<li>解析原理<ul>
<li>实例化一个 <code>beautifulsoup</code> 的对象，且将待解析的页面源码数据加载到该对象中</li>
<li>调用 <code>beautifulsoup</code> 对象中相关方法或者属性进行标签定位和文本数据的提取</li>
</ul>
</li>
<li>环境安装： <code>pip install bs4</code></li>
<li><code>Beautifulsoup</code> 对象的实例化：<ul>
<li><code>BeautifulSoup(fp, &#39;lxml&#39;)</code> : 用来将本地存储的 <code>html</code> 文档中的数据进行解析</li>
<li><code>BeautifulSoup(page_text, &#39;lxml&#39;)</code> ：用来将互联网上请求到的页面源码数据进行解析</li>
</ul>
</li>
<li>标签定位<ul>
<li><code>soup.tagName</code> ：只可以定位到第一次出现的 <code>tagName</code> 标签</li>
<li><code>soup.find(&#39;tagName&#39;, attrName=&#39;value&#39;)</code> ：属性定位，例： <code>soup.find(&#39;div&#39;, class_=&#39;aaa&#39;)</code></li>
<li><code>soup.find_all</code> ：跟 <code>find</code> 用法一样， <code>find_all</code> 返回的是列表</li>
<li><code>soup.select(&#39;选择器&#39;)</code>:<ul>
<li>类选择器: <code>.classname</code></li>
<li><code>id</code> 选择器: <code>#id</code></li>
<li>层级选择<ul>
<li><code>&gt;</code> ：表示一个层级</li>
<li>空格：表示多个层级</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>取数据<ul>
<li><code>.text</code> ：返回的是该标签下所有的文本内容</li>
<li><code>.string</code> ：返回的是该标签直系的文本内容</li>
</ul>
</li>
<li>取属性: <code>tag[&#39;attrName&#39;]</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬取三国全篇内容</span></span><br><span class="line"><span class="comment"># URL:http://shicimingju.com/book/sanguoyanyi.html</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">main_url = <span class="string">'http://shicimingju.com/book/sanguoyanyi.html'</span></span><br><span class="line">page_text = requests.get(url=main_url, headers=headers).text</span><br><span class="line">fp = open(<span class="string">'./sanguo.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 数据解析：章节标题，详情页url，章节内容</span></span><br><span class="line">soup = BeautifulSoup(page_text, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="comment"># 定位到的所有的符合要求的a标签</span></span><br><span class="line">a_list = soup.select(<span class="string">'.book-mulu &gt; ul &gt; li &gt; a'</span>)</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> a_list:</span><br><span class="line">    title = a.string</span><br><span class="line">    detail_url = <span class="string">'http://shicimingju.com'</span>+a[<span class="string">'href'</span>]</span><br><span class="line">    <span class="comment"># 对详情页发起请求解析出章节内容</span></span><br><span class="line">    page_text_detail = requests.get(url=detail_url, headers=headers).text</span><br><span class="line">    soup = BeautifulSoup(page_text_detail, <span class="string">'lxml'</span>)</span><br><span class="line">    div_tag = soup.find(<span class="string">'div'</span>, class_=<span class="string">'chapter_content'</span>)</span><br><span class="line">    content = div_tag.text</span><br><span class="line">    fp.write(title+<span class="string">':'</span>+content+<span class="string">'\n'</span>)</span><br><span class="line">    print(title,<span class="string">'保存成功'</span>)</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<h2 id="xpath数据解析"><a href="#xpath数据解析" class="headerlink" title="xpath数据解析"></a><strong>xpath数据解析</strong></h2><ul>
<li>环境安装： <code>pip install lxml</code></li>
<li>解析原理: <code>html</code> 标签是以树状的形式进行展示<ol>
<li>实例化一个 <code>etree</code> 的对象，且将待解析的页面源码数据加载到该对象中</li>
<li>调用 <code>etree</code> 对象的 <code>xpath</code> 方法结合着不同的xpath表达式实现标签的定位和数据提取</li>
</ol>
</li>
<li>实例化 <code>etree</code> 对象<ul>
<li><code>etree.parse(&#39;filename&#39;)</code> :将本地 <code>html</code> 文档加载到该对象中</li>
<li><code>etree.HTML(page_text)</code> :网站获取的页面数据加载到该对象</li>
</ul>
</li>
<li>标签定位：<ul>
<li>最左侧的 <code>/</code> ：如果 <code>xpath</code> 表达式最左侧是以 <code>/</code> 开头则表示该 <code>xpath</code> 表达式一定要从根标签开始定位指定标签（忽略）</li>
<li>非最左侧的 <code>/</code> ：表示一个层级</li>
<li>非左侧的 <code>//</code> ：表示多个层级</li>
<li>最左侧的 <code>//</code> ： <code>xpath</code> 表达式可以从任意位置进行标签定位</li>
<li>属性定位：<ul>
<li><code>tagName[@attrName=&quot;value&quot;]</code></li>
<li>例： <code>tree.xpath(&#39;//div[@class=&quot;song&quot;]&#39;)</code></li>
</ul>
</li>
<li>索引定位：<ul>
<li><code>tag[index]</code>( <code>index</code> 从1开始)</li>
<li>例： <code>tree.xpath(&#39;//div[@class=&quot;song&quot;]/p[2]&#39;)</code></li>
</ul>
</li>
</ul>
</li>
<li>取文本<ul>
<li><code>/text()</code> :直系文本内容</li>
<li><code>//text()</code> :所有的文本内容</li>
</ul>
</li>
<li>取属性<ul>
<li><code>/@attrName</code></li>
<li>例： <code>tree.xpath(&#39;//a[@id=&quot;feng&quot;]/@href&#39;)</code></li>
</ul>
</li>
<li>局部数据解析：<ul>
<li>将定位到的页面中的标签作为待解析的数据，再次使用 <code>xpath</code> 表达式解析待解析的数据。</li>
<li>在局部数据解析的时候， <code>xpath</code> 表达式中要使用 <code>./</code> 的操作， <code>./</code> 表示的就是当前的局部数据。</li>
</ul>
</li>
<li><code>xpath</code> 返回的是列表，使用时需要加下标</li>
<li><code>xpath</code> 表达式中不可以出现 <code>tbody</code> 标签<ul>
<li>例：<code>tree.xpath(&#39;//*[@id=&quot;ip_list&quot;]/tbody/tr&#39;)</code> </li>
<li>应写成 <code>tree.xpath(&#39;//*[@id=&quot;ip_list&quot;]//tr&#39;)</code></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">使用xpath爬取图片名称和图片数据</span></span><br><span class="line"><span class="string">URL:http://pic.netbian.com/4kmeinv/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 爬取第一页</span></span><br><span class="line">dirname = <span class="string">'girlslib'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dirname):</span><br><span class="line">    os.mkdir(dirname)</span><br><span class="line">url = <span class="string">'http://pic.netbian.com/4kmeinv/'</span></span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">response.encoding = <span class="string">'gbk'</span> <span class="comment"># 乱码问题用encoding换编码格式</span></span><br><span class="line">page_text = response.text</span><br><span class="line"><span class="comment"># 图片名称+图片数据</span></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line"><span class="comment"># 存储的是定位到的指定的li标签</span></span><br><span class="line">li_list = tree.xpath(<span class="string">'//div[@class="slist"]/ul/li'</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    title = li.xpath(<span class="string">'./a/img/@alt'</span>)[<span class="number">0</span>]+<span class="string">'.jpg'</span> <span class="comment"># 进行局部数据解析</span></span><br><span class="line">    img_src = <span class="string">'http://pic.netbian.com'</span>+li.xpath(<span class="string">'./a/img/@src'</span>)[<span class="number">0</span>]</span><br><span class="line">    img_data = requests.get(url=img_src, headers=headers).content</span><br><span class="line">    img_path = dirname+<span class="string">'/'</span>+title</span><br><span class="line">    <span class="keyword">with</span> open(img_path, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(img_data)</span><br><span class="line">    print(title, <span class="string">'保存成功'</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># 爬取多页</span></span><br><span class="line"><span class="string">dirname = 'girlslib2'</span></span><br><span class="line"><span class="string">if not os.path.exists(dirname):</span></span><br><span class="line"><span class="string">    os.mkdir(dirname)</span></span><br><span class="line"><span class="string"># 定义一个通用的url模板</span></span><br><span class="line"><span class="string">url = 'http://pic.netbian.com/4kmeinv/index_%d.html'</span></span><br><span class="line"><span class="string">for page in range(1,6):</span></span><br><span class="line"><span class="string">    if page == 1:</span></span><br><span class="line"><span class="string">        new_url = 'http://pic.netbian.com/4kmeinv/'</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        new_url = format(url%page)</span></span><br><span class="line"><span class="string">    response = requests.get(url=new_url, headers=headers)</span></span><br><span class="line"><span class="string">    response.encoding = 'gbk' # 乱码问题用encoding换编码格式</span></span><br><span class="line"><span class="string">    page_text = response.text</span></span><br><span class="line"><span class="string">    # 图片名称+图片数据</span></span><br><span class="line"><span class="string">    tree = etree.HTML(page_text)</span></span><br><span class="line"><span class="string">    # 存储的是定位到的指定的li标签</span></span><br><span class="line"><span class="string">    li_list = tree.xpath('//div[@class="slist"]/ul/li')</span></span><br><span class="line"><span class="string">    for li in li_list:</span></span><br><span class="line"><span class="string">        title = li.xpath('./a/img/@alt')[0]+'.jpg' # 进行局部数据解析</span></span><br><span class="line"><span class="string">        img_src = 'http://pic.netbian.com'+li.xpath('./a/img/@src')[0]</span></span><br><span class="line"><span class="string">        img_data = requests.get(url=img_src, headers=headers).content</span></span><br><span class="line"><span class="string">        img_path = dirname+'/'+title</span></span><br><span class="line"><span class="string">        with open(img_path, 'wb') as fp:</span></span><br><span class="line"><span class="string">            fp.write(img_data)</span></span><br><span class="line"><span class="string">        print(title, '保存成功')</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<ul>
<li>要求解析出携带 <code>html</code> 标签的局部数据时，使用 <code>bs4</code> ， <code>bs4</code> 在实现标签定位的时候返回的直接就是定位到标签对应的字符串数据</li>
<li><code>xpath</code> 表达式如何更加具有通用性：在 <code>xpath</code> 表达式中使用 <code>|</code> ，可以表示左右两侧的子 <code>xpath</code> 表达式同时生效或者一个生效</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将https://www.aqistudy.cn/historydata/所有的城市名称解析出来</span></span><br><span class="line">url = <span class="string">'https://www.aqistudy.cn/historydata/'</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers).text</span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line"><span class="comment"># hot_cities = tree.xpath('//div[@class="bottom"]/ul/li/a/text()')</span></span><br><span class="line"><span class="comment"># all_cities = tree.xpath('//div[@class="bottom"]/ul/div[2]/li/a/text()')</span></span><br><span class="line">tree.xpath(<span class="string">'//div[@class="bottom"]/ul/li/a/text() | //div[@class="bottom"]/ul/div[2]/li/a/text()'</span>)</span><br><span class="line"><span class="comment"># 同时取出热门城市和所有城市</span></span><br></pre></td></tr></table></figure>
<h2 id="实验代码-1"><a href="#实验代码-1" class="headerlink" title="实验代码"></a><strong>实验代码</strong></h2><ul>
<li>反爬机制：图片懒加载<ul>
<li>广泛应用在了一些图片的网站中</li>
<li>只有当图片被显示在浏览器可视化范围之内才会将 <code>img</code> 的伪属性变成真正的属性</li>
<li>如果是 <code>requests</code> 发起的请求， <code>requests</code> 请求是没有可视化范围</li>
</ul>
</li>
<li>破解方法：解析 <code>img</code> 伪属性的属性值（图片地址）<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 伪属性src2，即真实的图片地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">target</span>=<span class="string">"_blank"</span> <span class="attr">href</span>=<span class="string">"http://sc.chinaz.com/tupian/190209016733.htm"</span> <span class="attr">alt</span>=<span class="string">"梦幻唯美星空图片"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src2</span>=<span class="string">"http://pic.sc.chinaz.com/Files/pic/pic9/201901/zzpic16294_s.jpg"</span> <span class="attr">alt</span>=<span class="string">"梦幻唯美星空图片"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 显示属性src，并非真正的图片地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">target</span>=<span class="string">"_blank"</span> <span class="attr">href</span>=<span class="string">"http://sc.chinaz.com/tupian/190209016733.htm"</span> <span class="attr">alt</span>=<span class="string">"梦幻唯美星空图片"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">alt</span>=<span class="string">"梦幻唯美星空图片"</span> <span class="attr">src</span>=<span class="string">"http://pic.sc.chinaz.com/Files/pic/pic9/201901/zzpic16294_s.jpg"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>爬取免费简历模板</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">dirname = <span class="string">'Jianlimuban'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dirname):</span><br><span class="line">    os.mkdir(dirname)</span><br><span class="line">url_type = <span class="string">'http://sc.chinaz.com/jianli/free_%d.html'</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:</span><br><span class="line">        url = <span class="string">'http://sc.chinaz.com/jianli/free.html'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = format(url_type%page)</span><br><span class="line">    response = requests.get(url=url, headers=headers)</span><br><span class="line">    response.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    page_text = response.text</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    div_list = tree.xpath(<span class="string">'//div[@id="container"]/div'</span>)</span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">        title = div.xpath(<span class="string">'./a/img/@alt'</span>)[<span class="number">0</span>]</span><br><span class="line">        new_src = div.xpath(<span class="string">'./a/@href'</span>)[<span class="number">0</span>]</span><br><span class="line">        rp = requests.get(url=new_src, headers=headers)</span><br><span class="line">        rp.encoding = <span class="string">'utf-8'</span></span><br><span class="line">        new_text = rp.text</span><br><span class="line">        tree = etree.HTML(new_text)</span><br><span class="line">        li_list = tree.xpath(<span class="string">'//ul[@class="clearfix"]/li'</span>)</span><br><span class="line">        name = li_list[<span class="number">0</span>].xpath(<span class="string">'./a/text()'</span>)</span><br><span class="line">        address = li_list[<span class="number">0</span>].xpath(<span class="string">'./a/@href'</span>)[<span class="number">0</span>]</span><br><span class="line">        path = dirname+<span class="string">'/'</span>+title+<span class="string">'.'</span>+address.split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> str(address).endswith(<span class="string">".rar"</span>):</span><br><span class="line">            urllib.request.urlretrieve(address, path)</span><br><span class="line">            print(title, <span class="string">"下载成功"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<ul>
<li>爬取高清图片</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">dirname = <span class="string">'sky_picture'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dirname):</span><br><span class="line">    os.mkdir(dirname)</span><br><span class="line">url_type = <span class="string">'http://sc.chinaz.com/tupian/xingkongtupian_%d.html'</span></span><br><span class="line"><span class="keyword">for</span> url_n <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    <span class="keyword">if</span> url_n == <span class="number">1</span>:</span><br><span class="line">        url = <span class="string">'http://sc.chinaz.com/tupian/xingkongtupian.html'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = format(url_type%url_n)</span><br><span class="line">    response = requests.get(url=url, headers=headers)</span><br><span class="line">    response.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    page_text = response.text</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    img_list = tree.xpath(<span class="string">'//div[@id="container"]/div'</span>)</span><br><span class="line">    <span class="keyword">for</span> div <span class="keyword">in</span> img_list:</span><br><span class="line">        title = div.xpath(<span class="string">'./div/a/img/@alt'</span>)[<span class="number">0</span>]</span><br><span class="line">        src = div.xpath(<span class="string">'./div/a/img/@src2'</span>)[<span class="number">0</span>]</span><br><span class="line">        src = src.replace(<span class="string">'_s.'</span>,<span class="string">'.'</span>)</span><br><span class="line">        path = dirname+<span class="string">'/'</span>+title+<span class="string">'.'</span>+src.split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">        urllib.request.urlretrieve(src, path)</span><br><span class="line">        print(title, src,<span class="string">"保存成功"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>爬取梨视频中的短视频数据：<a href="https://www.pearvideo.com/">https://www.pearvideo.com/</a></li>
<li>将最热板块下的短视频数据进行爬取且存储到本地</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">dirname = <span class="string">'梨视频'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dirname):</span><br><span class="line">    os.mkdir(dirname)</span><br><span class="line">url = <span class="string">'https://www.pearvideo.com/category_8'</span></span><br><span class="line">response = requests.get(url=url, headers=headers)</span><br><span class="line">page_text = response.text</span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">li_list = tree.xpath(<span class="string">'//ul[@id="listvideoListUl"]/li'</span>)</span><br><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">    title = li.xpath(<span class="string">'./div/a/div[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">    url = <span class="string">'https://www.pearvideo.com/'</span>+li.xpath(<span class="string">'./div/a/@href'</span>)[<span class="number">0</span>]</span><br><span class="line">    rp = requests.get(url=url, headers=headers).text</span><br><span class="line">    tree = etree.HTML(rp)</span><br><span class="line">    address = tree.xpath(<span class="string">'//div[@class="details-main vertical-details cmmain"]/script//text()'</span>)[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">12</span>][<span class="number">8</span>:<span class="number">-1</span>]</span><br><span class="line">    path = dirname+<span class="string">'/'</span>+title+<span class="string">'.'</span>+address.split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">    urllib.request.urlretrieve(address, path)</span><br><span class="line">    print(address)</span><br><span class="line">    print(title, <span class="string">"下载成功"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>需求：将段子王中的段子内容爬取到本地：<a href="https://duanziwang.com/">https://duanziwang.com/</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># bs4 BeautifulSoup</span></span><br><span class="line">url_type = <span class="string">'https://duanziwang.com/category/一句话段子/%d/'</span></span><br><span class="line">fp = open(<span class="string">'段子.txt'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">    url = format(url_type%page)</span><br><span class="line">    response = requests.get(url=url, headers=headers)</span><br><span class="line">    page_text = response.text</span><br><span class="line">    soup = BeautifulSoup(page_text, <span class="string">'lxml'</span>)</span><br><span class="line">    post_list = soup.select(<span class="string">'.row &gt; main &gt; article'</span>)</span><br><span class="line">    <span class="keyword">for</span> post <span class="keyword">in</span> post_list:</span><br><span class="line">        title = post.find(<span class="string">'h1'</span>, class_=<span class="string">'post-title'</span>).string</span><br><span class="line">        content = post.find(<span class="string">'div'</span>, class_=<span class="string">'post-content'</span>).text</span><br><span class="line">        fp.write(title+<span class="string">'\n'</span>+content+<span class="string">'\n\n'</span>)</span><br><span class="line">        print(title, <span class="string">'保存成功'</span>)</span><br><span class="line">fp.close()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># etree xpath</span></span><br><span class="line"><span class="string">url_type = 'https://duanziwang.com/category/一句话段子/%d/'</span></span><br><span class="line"><span class="string">fp = open('段子2.txt', 'w', encoding='utf-8')</span></span><br><span class="line"><span class="string">for page in range(1,6):</span></span><br><span class="line"><span class="string">    url = format(url_type%page)</span></span><br><span class="line"><span class="string">    response = requests.get(url=url, headers=headers)</span></span><br><span class="line"><span class="string">    page_text = response.text</span></span><br><span class="line"><span class="string">    tree = etree.HTML(page_text)</span></span><br><span class="line"><span class="string">    post_list = tree.xpath('//main[@class="col-md-8 main-content"]/article')</span></span><br><span class="line"><span class="string">    for post in post_list:</span></span><br><span class="line"><span class="string">        title = post.xpath('./div[1]/h1/a/text()')[0]</span></span><br><span class="line"><span class="string">        content = post.xpath('./div[2]/p//text()')[0]</span></span><br><span class="line"><span class="string">        fp.write(title+'\n'+content+'\n\n')</span></span><br><span class="line"><span class="string">        print(title, '保存成功')</span></span><br><span class="line"><span class="string">fp.close()</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>
<h1 id="模拟登录"><a href="#模拟登录" class="headerlink" title="模拟登录"></a><strong>模拟登录</strong></h1><h2 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a><strong>Cookie</strong></h2><ul>
<li><code>cookie</code> 是存储在客户端的一组键值对</li>
<li><code>web</code> 中 <code>cookie</code> 的典型应用：免密登录</li>
<li><code>cookie</code> 和爬虫之间的关联：<ul>
<li>有时对一张页面进行请求时，如果请求的过程中不携带 <code>cookie</code> 则无法请求到正确的页面数据</li>
<li><code>cookie</code> 是爬虫中非常典型且常见的反爬机制</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">需求：爬取雪球网中的咨询信息:https://xueqiu.com/</span></span><br><span class="line"><span class="string">分析：</span></span><br><span class="line"><span class="string">1.判定爬取的咨询数据是否为动态加载</span></span><br><span class="line"><span class="string">相关的更多资讯数据是动态加载的，滚轮滑动到底的时候会动态加载出更多资讯数据。</span></span><br><span class="line"><span class="string">2.定位到ajax请求的数据包，提取出请求的url，响应数据为json形式的咨询数据</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">'https://xueqiu.com/v4/statuses/public_timeline_by_category.json?since_id=-1&amp;max_id=20370797&amp;count=15&amp;category=-1'</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers).json()</span><br><span class="line">print(page_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line">&#123;<span class="string">'error_description'</span>: <span class="string">'遇到错误，请刷新页面或者重新登录帐号后再试'</span>,</span><br><span class="line"> <span class="string">'error_uri'</span>: <span class="string">'/v4/statuses/public_timeline_by_category.json'</span>,</span><br><span class="line"> <span class="string">'error_data'</span>: <span class="literal">None</span>,</span><br><span class="line"> <span class="string">'error_code'</span>: <span class="string">'400016'</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>问题：没有请求到我们想要的数据</li>
<li>原因：没有严格意义上模拟浏览器发送请求</li>
<li>解决：可以将浏览器发请求携带的请求头，全部粘贴在 <code>headers</code> 字典中，将 <code>headers</code> 作用到 <code>requests</code> 的请求操作中即可。</li>
<li><code>cookie</code> 的处理方式：<ol>
<li>手动处理<ul>
<li>将抓包工具中的 <code>cookie</code> 粘贴在 <code>headers</code>中</li>
<li>弊端： <code>cookie</code> 如果过了有效时长则该方式失效</li>
</ul>
</li>
<li>自动处理<ul>
<li>基于 <code>Session</code> 对象实现自动处理</li>
<li>如何获取一个 <code>session</code> 对象： <code>requests.Session()</code> 返回一个 <code>session</code> 对象</li>
</ul>
</li>
</ol>
</li>
<li><code>session</code> 对象的作用：<ul>
<li>该对象可以向 <code>requests</code> 一样调用 <code>get</code> 和 <code>post</code> 发起指定的请求</li>
<li>如果在使用 <code>session</code> 发请求的过程中如果产生了 <code>cookie</code> ，则 <code>cookie</code> 会被自动存储到该 <code>session</code> 对象中</li>
<li>意味着下次再次使用 <code>session</code> 对象发起请求，则该次请求就是携带 <code>cookie</code> 进行的请求发送。</li>
</ul>
</li>
<li>在爬虫中使用 <code>session</code> 的时候， <code>session</code> 对象至少会被使用两次<ul>
<li>第一次使用 <code>session</code> 是为了将 <code>cookie</code> 捕获且存储到 <code>session</code> 对象中</li>
<li>第二次的时候就是携带 <code>cookie</code> 进行的请求发送</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span></span><br><span class="line">&#125;</span><br><span class="line">session = requests.Session() <span class="comment"># 创建session对象</span></span><br><span class="line"><span class="comment"># 第一次使用session捕获且存储cookie</span></span><br><span class="line">main_url = <span class="string">'https://xueqiu.com/'</span></span><br><span class="line">session.get(main_url, headers=headers) <span class="comment"># 捕获且存储cookie</span></span><br><span class="line">url = <span class="string">'https://xueqiu.com/v4/statuses/public_timeline_by_category.json?since_id=-1&amp;max_id=20370797&amp;count=15&amp;category=-1'</span></span><br><span class="line">page_text = session.get(url=url, headers=headers).json()</span><br><span class="line">page_text</span><br></pre></td></tr></table></figure>
<h2 id="代理操作"><a href="#代理操作" class="headerlink" title="代理操作"></a><strong>代理操作</strong></h2><ul>
<li>在爬虫中，所谓的代理指的是代理服务器</li>
<li>代理服务器的作用是用来转发请求和响应</li>
<li>在爬虫中需要使用代理服务器的原因<ul>
<li>爬虫在短时间内对服务器发起了高频的请求，服务器会检测到该异常的行为请求，然后将该请求对应设备的 <code>ip</code> 禁掉，就意味这 <code>client</code> 设备无法对服务器端再次进行请求发送（ <code>ip</code> 被禁掉）</li>
<li>如果 <code>ip</code> 被禁，使用代理服务器进行请求转发，破解 <code>ip</code> 被禁的反爬机制，使用代理后，服务器端接收到的请求对应的 <code>ip</code> 地址就是代理服务器而不是真正的客户端</li>
</ul>
</li>
<li>代理服务器拥有不同的匿名度：<ul>
<li>透明代理：如果使用了该形式的代理，服务器端知道你使用了代理机制也知道你的真实 <code>ip</code></li>
<li>匿名代理：知道你使用代理，但是不知道你的真实 <code>ip</code></li>
<li>高匿代理：不知道你使用了代理也不知道你的真实 <code>ip</code></li>
</ul>
</li>
<li>代理的类型：<ul>
<li><code>https</code> ：代理只能转发 <code>https</code> 协议的请求</li>
<li><code>http</code> ：转发 <code>http</code> 的请求</li>
</ul>
</li>
</ul>
<h2 id="验证码的识别"><a href="#验证码的识别" class="headerlink" title="验证码的识别"></a><strong>验证码的识别</strong></h2><ul>
<li>基于线上的打码平台识别验证码</li>
<li>打码平台：超级鹰（可以识别 <code>12306</code> ）<ol>
<li>注册（<a href="http://www.chaojiying.com/%EF%BC%89">http://www.chaojiying.com/）</a></li>
<li>登录（用户中心的身份）</li>
<li>查询余额</li>
<li>创建一个软件 <code>ID</code></li>
<li>下载一个示例代码</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Chaojiying_Client</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, username, password, soft_id)</span>:</span></span><br><span class="line">        self.username = username</span><br><span class="line">        password =  password.encode(<span class="string">'utf8'</span>)</span><br><span class="line">        self.password = md5(password).hexdigest()</span><br><span class="line">        self.soft_id = soft_id</span><br><span class="line">        self.base_params = &#123;</span><br><span class="line">            <span class="string">'user'</span>: self.username,</span><br><span class="line">            <span class="string">'pass2'</span>: self.password,</span><br><span class="line">            <span class="string">'softid'</span>: self.soft_id,</span><br><span class="line">        &#125;</span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">'Connection'</span>: <span class="string">'Keep-Alive'</span>,</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)'</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">PostPic</span><span class="params">(self, im, codetype)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        im: 图片字节</span></span><br><span class="line"><span class="string">        codetype: 题目类型 参考 http://www.chaojiying.com/price.html</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">'codetype'</span>: codetype,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        files = &#123;<span class="string">'userfile'</span>: (<span class="string">'ccc.jpg'</span>, im)&#125;</span><br><span class="line">        r = requests.post(<span class="string">'http://upload.chaojiying.net/Upload/Processing.php'</span>, data=params, files=files, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ReportError</span><span class="params">(self, im_id)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        im_id:报错题目的图片ID</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">'id'</span>: im_id,</span><br><span class="line">        &#125;</span><br><span class="line">        params.update(self.base_params)</span><br><span class="line">        r = requests.post(<span class="string">'http://upload.chaojiying.net/Upload/ReportError.php'</span>, data=params, headers=self.headers)</span><br><span class="line">        <span class="keyword">return</span> r.json()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tranformImgCode</span><span class="params">(imgPath, imgType)</span>:</span></span><br><span class="line">    chaojiying = Chaojiying_Client(<span class="string">'xxxx'</span>, <span class="string">'xxxx'</span>, <span class="string">'904445'</span>)<span class="comment">#用户中心&gt;&gt;软件ID 生成一个替换 96001</span></span><br><span class="line">    im = open(imgPath, <span class="string">'rb'</span>).read()<span class="comment">#本地图片文件路径 来替换 a.jpg 有时WIN系统须要//</span></span><br><span class="line">    <span class="keyword">return</span> chaojiying.PostPic(im, imgType)[<span class="string">'pic_str'</span>]<span class="comment">#1902 验证码类型  官方网站&gt;&gt;价格体系 3.4+版 print 后要加()</span></span><br><span class="line">print(tranformImgCode(<span class="string">'./a.jpg'</span>, <span class="number">1902</span>))</span><br></pre></td></tr></table></figure>
<h2 id="模拟登录-1"><a href="#模拟登录-1" class="headerlink" title="模拟登录"></a><strong>模拟登录</strong></h2><ul>
<li>对点击登录按钮对应的请求进行发送（ <code>post</code> 请求）</li>
<li>处理请求参数：<ul>
<li>用户名</li>
<li>密码</li>
<li>验证码</li>
<li>其他的防伪参数</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 识别验证码</span></span><br><span class="line">url = <span class="string">'https://so.gushiwen.org/user/login.aspx?from=http://so.gushiwen.org/user/collect.aspx'</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers).text</span><br><span class="line"><span class="comment"># 解析验证码图片的地址</span></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">img_src = <span class="string">'https://so.gushiwen.org'</span>+tree.xpath(<span class="string">'//*[@id="imgCode"]/@src'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 将验证码图片保存到本地</span></span><br><span class="line">img_data = requests.get(url=img_src, headers=headers).content</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./code.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(img_data)</span><br><span class="line"><span class="comment"># 识别验证码</span></span><br><span class="line">code_text = tranformImgCode(<span class="string">'./code.jpg'</span>, <span class="number">1902</span>)</span><br><span class="line">print(code_text)</span><br><span class="line">login_url = <span class="string">'https://so.gushiwen.org/user/login.aspx?from=http%3a%2f%2fso.gushiwen.org%2fuser%2fcollect.aspx'</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'__VIEWSTATE'</span>:<span class="string">'8ICDQqsZB6wCZ8FyWZRlI6tefztp2jqYwtS2FRkyiNYGBApdq9gEyf0mMJDYBkhebLMPuybEkJezWm3i+iaw/OtfPmjKG9WyUtVC+P/7fgWNu01A/LQy0fRmssI='</span>,</span><br><span class="line">    <span class="string">'__VIEWSTATEGENERATOR'</span>:<span class="string">'C93BE1AE'</span>,</span><br><span class="line">    <span class="string">'from'</span>:<span class="string">'http://so.gushiwen.org/user/collect.aspx'</span>,</span><br><span class="line">    <span class="string">'email'</span>:<span class="string">'xxxxx'</span>,</span><br><span class="line">    <span class="string">'pwd'</span>:<span class="string">'xxxxx'</span>,</span><br><span class="line">    <span class="string">'code'</span>:code_text,<span class="comment"># 动态变化</span></span><br><span class="line">    <span class="string">'denglu'</span>:<span class="string">'登录'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 对点击登录按钮发起请求</span></span><br><span class="line">page_text_login = requests.post(url=login_url, headers=headers, data=data).text</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./gushiwen.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text_login)</span><br></pre></td></tr></table></figure>
<ul>
<li>结果：模拟登录失败</li>
<li>原因： <code>cookie</code></li>
<li>不可能是验证码的问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 携带cookie进行模拟登录</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">session = requests.Session()</span><br><span class="line"><span class="comment"># 识别验证码</span></span><br><span class="line">url = <span class="string">'https://so.gushiwen.org/user/login.aspx?from=http://so.gushiwen.org/user/collect.aspx'</span></span><br><span class="line">page_text = session.get(url=url, headers=headers).text</span><br><span class="line"><span class="comment"># 解析验证码图片的地址</span></span><br><span class="line">tree = etree.HTML(page_text)</span><br><span class="line">img_src = <span class="string">'https://so.gushiwen.org'</span>+tree.xpath(<span class="string">'//*[@id="imgCode"]/@src'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 将验证码图片保存到本地</span></span><br><span class="line">img_data = session.get(url=img_src, headers=headers).content</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./code.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(img_data)</span><br><span class="line"><span class="comment"># 识别验证码</span></span><br><span class="line">code_text = tranformImgCode(<span class="string">'./code.jpg'</span>, <span class="number">1902</span>)</span><br><span class="line">print(code_text)</span><br><span class="line">login_url = <span class="string">'https://so.gushiwen.org/user/login.aspx?from=http%3a%2f%2fso.gushiwen.org%2fuser%2fcollect.aspx'</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">'__VIEWSTATE'</span>:<span class="string">'8ICDQqsZB6wCZ8FyWZRlI6tefztp2jqYwtS2FRkyiNYGBApdq9gEyf0mMJDYBkhebLMPuybEkJezWm3i+iaw/OtfPmjKG9WyUtVC+P/7fgWNu01A/LQy0fRmssI='</span>,</span><br><span class="line">    <span class="string">'__VIEWSTATEGENERATOR'</span>:<span class="string">'C93BE1AE'</span>,</span><br><span class="line">    <span class="string">'from'</span>:<span class="string">'http://so.gushiwen.org/user/collect.aspx'</span>,</span><br><span class="line">    <span class="string">'email'</span>:<span class="string">'xxxx'</span>,</span><br><span class="line">    <span class="string">'pwd'</span>:<span class="string">'xxxx'</span>,</span><br><span class="line">    <span class="string">'code'</span>:code_text,<span class="comment"># 动态变化</span></span><br><span class="line">    <span class="string">'denglu'</span>:<span class="string">'登录'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 对点击登录按钮发起请求</span></span><br><span class="line">page_text_login = session.post(url=login_url, headers=headers, data=data).text</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./gushiwen.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(page_text_login)</span><br></pre></td></tr></table></figure>
<ul>
<li>在请求参数中如果看到一组乱序的请求参数，最好去验证这组请求参数是否为动态变化。<ul>
<li>判断：对该网页进行两次抓包，判断参数是否相同，不相同则为动态变化</li>
</ul>
</li>
<li>处理：<ul>
<li>方式1：常规来讲一般动态变化的请求参数会被隐藏在前台页面中，那么我们就要去前台页面源码中去找</li>
<li>方式2：如果前台页面没有的话，我们就可以基于抓包工具进行全局搜索。</li>
</ul>
</li>
</ul>
<h1 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a><strong>selenium</strong></h1><h2 id="selenium基础"><a href="#selenium基础" class="headerlink" title="selenium基础"></a><strong>selenium基础</strong></h2><ul>
<li>概念：基于浏览器自动化的模块</li>
<li>自动化：可以通过代码指定一系列的行为动作，然后将其作用到浏览器中</li>
<li>环境安装： <code>pip install selenium</code></li>
<li><code>selenium</code> 和爬虫之间的关联<ul>
<li>1.便捷的捕获到任意形式动态加载的数据（可见即可得）</li>
<li>2.实现模拟登录</li>
</ul>
</li>
<li><code>selenium</code> 的弊端：效率低</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="comment"># 1.基于浏览器的驱动程序实例化一个浏览器对象</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">'./chromedriver.exe'</span>)</span><br><span class="line"><span class="comment"># 对目的网站发起请求</span></span><br><span class="line">bro.get(<span class="string">'https://www.jd.com/'</span>)</span><br><span class="line"><span class="comment"># 标签定位</span></span><br><span class="line">search_text = bro.find_element_by_xpath(<span class="string">'//*[@id="key"]'</span>)</span><br><span class="line"><span class="comment"># 向标签中录入数据</span></span><br><span class="line">search_text.send_keys(<span class="string">'iphoneX'</span>)</span><br><span class="line">btn = bro.find_element_by_xpath(<span class="string">'//*[@id="search"]/div/div[2]/button'</span>)</span><br><span class="line">btn.click()</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 在搜索结果页面进行滚轮向下滑动的操作（执行js操作：js注入）</span></span><br><span class="line">bro.execute_script(<span class="string">'window.scrollTo(0,document.body.scrollHeight)'</span>)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>
<ul>
<li>捕获动态加载的数据</li>
<li>药监总局为例：<a href="http://125.35.6.84:81/xk/">http://125.35.6.84:81/xk/</a></li>
<li>前三页所有企业名称爬取</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">url = <span class="string">'http://125.35.6.84:81/xk/'</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">'./chromedriver.exe'</span>)</span><br><span class="line">bro.get(url)</span><br><span class="line">page_text_list = []  <span class="comment"># 每一页的页面源码数据</span></span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 捕获到当前页面对应的页面源码数据</span></span><br><span class="line">page_text = bro.page_source <span class="comment"># 当前页面全部加载完毕后对应的所有数据</span></span><br><span class="line">page_text_list.append(page_text)</span><br><span class="line"><span class="comment"># 点击下一页</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    next_page = bro.find_element_by_xpath(<span class="string">'//*[@id="pageIto_next"]'</span>)</span><br><span class="line">    next_page.click()</span><br><span class="line">    sleep(<span class="number">1</span>)</span><br><span class="line">    page_text_list.append(bro.page_source)</span><br><span class="line"><span class="keyword">for</span> page_text <span class="keyword">in</span> page_text_list:</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    li_list = tree.xpath(<span class="string">'//*[@id="gzlist"]/li'</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        name = li.xpath(<span class="string">'./dl/@title'</span>)[<span class="number">0</span>]</span><br><span class="line">        print(name)</span><br><span class="line">sleep(<span class="number">2</span>)</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>
<h2 id="动作链ActionChains"><a href="#动作链ActionChains" class="headerlink" title="动作链ActionChains"></a><strong>动作链ActionChains</strong></h2><ul>
<li>动作链：一系列连续的动作（滑动动作）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">url = <span class="string">'https://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">'./chromedriver.exe'</span>)</span><br><span class="line">bro.get(url)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 如果通过find系列的函数进行标签定位，如果标签是存在于iframe下面，则会定位失败</span></span><br><span class="line"><span class="comment"># 解决方案：使用switch_to即可</span></span><br><span class="line">bro.switch_to.frame(<span class="string">'iframeResult'</span>)</span><br><span class="line">div_tag = bro.find_element_by_xpath(<span class="string">'//*[@id="draggable"]'</span>)</span><br><span class="line"><span class="comment"># 对div_tag进行滑动操作</span></span><br><span class="line">action = ActionChains(bro)</span><br><span class="line">action.click_and_hold(div_tag)  <span class="comment"># 点击且长按</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    <span class="comment"># perform让动作链立即执行</span></span><br><span class="line">    action.move_by_offset(<span class="number">10</span>,<span class="number">15</span>).perform()</span><br><span class="line">    sleep(<span class="number">0.5</span>)</span><br><span class="line">action.release()</span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>
<ul>
<li>有的网站会检测请求是否为 <code>selenium</code> 发起，如果是的话则让该次请求失败</li>
<li>规避检测的方法： <code>selenium</code> 接管 <code>chrome</code> 浏览器</li>
</ul>
<h2 id="12306模拟登录"><a href="#12306模拟登录" class="headerlink" title="12306模拟登录"></a><strong>12306模拟登录</strong></h2><ul>
<li>使用 <code>selenium</code> 打开登录页面</li>
<li>对当前 <code>selenium</code> 打开的这张页面进行截图</li>
<li>对当前图片局部区域（验证码区域）进行剪裁<ul>
<li>好处：将验证码图片和模拟登录进行一一对应</li>
</ul>
</li>
<li>使用超级鹰识别验证码图片（坐标）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> chaojiying</span><br><span class="line">bro =webdriver.Chrome(executable_path=<span class="string">"./chromedriver.exe"</span>)</span><br><span class="line">url = <span class="string">"https://kyfw.12306.cn/otn/resources/login.html"</span></span><br><span class="line">bro.get(url)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">bro.maximize_window()</span><br><span class="line">bro.find_element_by_xpath(<span class="string">"/html/body/div[2]/div[2]/ul/li[2]/a"</span>).click()</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 整张页面截图</span></span><br><span class="line">bro.save_screenshot(<span class="string">"aa.png"</span>)</span><br><span class="line"><span class="comment"># 局部图片剪裁</span></span><br><span class="line"><span class="comment"># 确定验证码图片对应的左上角和右下角的坐标（裁剪的区域）</span></span><br><span class="line">code_img_ele = bro.find_element_by_xpath(<span class="string">'//*[@id="J-loginImg"]'</span>)</span><br><span class="line">location = code_img_ele.location  <span class="comment"># 验证码图片左上角坐标x,y</span></span><br><span class="line">size = code_img_ele.size  <span class="comment"># 验证码标签对应的长和宽</span></span><br><span class="line"><span class="comment"># 左上角和右下角坐标</span></span><br><span class="line">rangle = (</span><br><span class="line">    int(location[<span class="string">'x'</span>]),</span><br><span class="line">    int(location[<span class="string">'y'</span>]),</span><br><span class="line">    int(location[<span class="string">'x'</span>]+size[<span class="string">'width'</span>]),</span><br><span class="line">    int(location[<span class="string">'y'</span>]+size[<span class="string">'height'</span>])</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 验证码图片区域确定</span></span><br><span class="line">i = Image.open(<span class="string">'./aa.png'</span>)</span><br><span class="line">code_img_name = <span class="string">'code.png'</span></span><br><span class="line">frame = i.crop(rangle)</span><br><span class="line">frame.save(code_img_name)</span><br><span class="line"><span class="comment"># 将验证码图片提交给超级鹰进行识别</span></span><br><span class="line">result = chaojiying.tranformImgCode(<span class="string">'code.png'</span>, <span class="number">9004</span>)</span><br><span class="line">print(result)</span><br><span class="line">all_list = []  <span class="comment"># 存储即将被点击的坐标[[x1,y1],[x2,y2]]</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">'|'</span> <span class="keyword">in</span> result:</span><br><span class="line">    list_1 = result.split(<span class="string">'|'</span>)</span><br><span class="line">    count_1 = len(list_1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(count_1):</span><br><span class="line">        xy_list = []</span><br><span class="line">        x = int(list_1[i].split(<span class="string">','</span>)[<span class="number">0</span>])</span><br><span class="line">        y = int(list_1[i].split(<span class="string">','</span>)[<span class="number">1</span>])</span><br><span class="line">        xy_list.append(x)</span><br><span class="line">        xy_list.append(y)</span><br><span class="line">        all_list.append(xy_list)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    x = int(result.split(<span class="string">','</span>)[<span class="number">0</span>])</span><br><span class="line">    y = int(result.split(<span class="string">','</span>)[<span class="number">1</span>])</span><br><span class="line">    xy_list = []</span><br><span class="line">    xy_list.append(x)</span><br><span class="line">    xy_list.append(y)</span><br><span class="line">    all_list.append(xy_list)</span><br><span class="line">print(all_list)</span><br><span class="line"><span class="comment"># 遍历列表，使用动作链对每一个列表元素对应的坐标位置进行点击</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> all_list:</span><br><span class="line">    x = l[<span class="number">0</span>]</span><br><span class="line">    y = l[<span class="number">1</span>]</span><br><span class="line">    ActionChains(bro).move_to_element_with_offset(code_img_ele, x, y).click().perform()</span><br><span class="line">    time.sleep(<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 输入用户名和密码</span></span><br><span class="line">bro.find_element_by_xpath(<span class="string">'//*[@id="J-userName"]'</span>).send_keys(<span class="string">'xxxxxx'</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">bro.find_element_by_xpath(<span class="string">'//*[@id="J-password"]'</span>).send_keys(<span class="string">'xxxxxx'</span>)</span><br><span class="line">time.sleep(<span class="number">1.5</span>)</span><br><span class="line">bro.find_element_by_xpath(<span class="string">'//*[@id="J-login"]'</span>).click()</span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<h2 id="余票监测"><a href="#余票监测" class="headerlink" title="余票监测"></a><strong>余票监测</strong></h2><ul>
<li><code>Cookie</code> 中有两项动态数据需要获取值</li>
<li>进行多次抓包寻找动态数值</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:68.0) Gecko/20100101 Firefox/68.0'</span>,</span><br><span class="line">&#125;</span><br><span class="line">city = &#123;</span><br><span class="line">    <span class="string">'北京北'</span>: <span class="string">'VAP'</span>,</span><br><span class="line">    <span class="string">'北京东'</span>: <span class="string">'BOP'</span>,</span><br><span class="line">    <span class="string">'北京'</span>: <span class="string">'BJP'</span>,</span><br><span class="line">    <span class="string">'北京南'</span>: <span class="string">'VNP'</span>,</span><br><span class="line">    <span class="string">'北京西'</span>: <span class="string">'BXP'</span>,</span><br><span class="line">    <span class="string">'广州南'</span>: <span class="string">'IZQ'</span>,</span><br><span class="line">    <span class="string">'重庆北'</span>: <span class="string">'CUW'</span>,</span><br><span class="line">    <span class="string">'重庆'</span>: <span class="string">'CQW'</span>,</span><br><span class="line">    <span class="string">'重庆南'</span>: <span class="string">'CRW'</span>,</span><br><span class="line">    <span class="string">'广州东'</span>: <span class="string">'GGQ'</span>,</span><br><span class="line">    <span class="string">'上海'</span>: <span class="string">'SHH'</span>,</span><br><span class="line">    <span class="string">'上海南'</span>: <span class="string">'SNH'</span>,</span><br><span class="line">    <span class="string">'上海虹桥'</span>: <span class="string">'AOH'</span>,</span><br><span class="line">    <span class="string">'齐齐哈尔'</span>: <span class="string">'QHX'</span>,</span><br><span class="line">&#125;</span><br><span class="line">session = requests.Session()</span><br><span class="line">Url = <span class="string">"https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=dc"</span></span><br><span class="line">session.get(url=Url, headers=headers)</span><br><span class="line">t = input(<span class="string">'输入出发时间(yyyy-mm-dd):'</span>)</span><br><span class="line">start = input(<span class="string">'请输入出发城市：'</span>)</span><br><span class="line">start = city[start]</span><br><span class="line">end = input(<span class="string">'请输入到达城市：'</span>)</span><br><span class="line">end = city[end]</span><br><span class="line">url = <span class="string">"https://kyfw.12306.cn/otn/leftTicket/query"</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'leftTicketDTO.train_date'</span>: t,</span><br><span class="line">    <span class="string">'leftTicketDTO.from_station'</span>: start,</span><br><span class="line">    <span class="string">'leftTicketDTO.to_station'</span>: end,</span><br><span class="line">    <span class="string">'purpose_codes'</span>: <span class="string">'ADULT'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">_jc_save_fromStation=%u91CD%u5E86%2CCQW; </span></span><br><span class="line"><span class="string">_jc_save_toStation=%u5317%u4EAC%2CBJP; </span></span><br><span class="line"><span class="string">这两项是Cookie中的动态数据</span></span><br><span class="line"><span class="string">末尾三个字母需要动态输入</span></span><br><span class="line"><span class="string">CQW表示出发地点为重庆</span></span><br><span class="line"><span class="string">BJP表示到达地点为北京</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">session.cookies[<span class="string">"_jc_save_fromStation"</span>] = <span class="string">"%u91CD%u5E86%2C"</span>+start</span><br><span class="line">session.cookies[<span class="string">"_jc_save_toStation"</span>] = <span class="string">"%u5317%u4EAC%2C"</span>+end</span><br><span class="line">json_data_list = session.get(url=url, headers=headers, params=params).json()[<span class="string">"data"</span>][<span class="string">"result"</span>]</span><br><span class="line">print(json_data_list)</span><br></pre></td></tr></table></figure>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a><a class="link-muted mr-2" rel="tag" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/04/27/%E8%B1%86%E7%93%A3%E7%88%AC%E8%99%AB/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">豆瓣爬虫</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/04/24/PyCharm%E6%B0%B8%E4%B9%85%E6%BF%80%E6%B4%BB/"><span class="level-item">PyCharm永久激活</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/touxiang.png" alt="CZH"></figure><p class="title is-size-4 is-block line-height-inherit">CZH</p><p class="is-size-6 is-block">犹豫，就会败北</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">15</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/flyness666" target="_blank" rel="noopener">关注我</a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#requests基础"><span class="mr-2">1</span><span>requests基础</span></a><ul class="menu-list"><li><a class="is-flex" href="#爬取静态网页内容"><span class="mr-2">1.1</span><span>爬取静态网页内容</span></a></li><li><a class="is-flex" href="#爬取动态网页内容"><span class="mr-2">1.2</span><span>爬取动态网页内容</span></a></li><li><a class="is-flex" href="#实验代码"><span class="mr-2">1.3</span><span>实验代码</span></a></li></ul></li><li><a class="is-flex" href="#数据解析"><span class="mr-2">2</span><span>数据解析</span></a><ul class="menu-list"><li><a class="is-flex" href="#数据解析-1"><span class="mr-2">2.1</span><span>数据解析</span></a></li><li><a class="is-flex" href="#爬取图片数据"><span class="mr-2">2.2</span><span>爬取图片数据</span></a></li><li><a class="is-flex" href="#正则数据解析"><span class="mr-2">2.3</span><span>正则数据解析</span></a></li><li><a class="is-flex" href="#bs4解析数据"><span class="mr-2">2.4</span><span>bs4解析数据</span></a></li><li><a class="is-flex" href="#xpath数据解析"><span class="mr-2">2.5</span><span>xpath数据解析</span></a></li><li><a class="is-flex" href="#实验代码-1"><span class="mr-2">2.6</span><span>实验代码</span></a></li></ul></li><li><a class="is-flex" href="#模拟登录"><span class="mr-2">3</span><span>模拟登录</span></a><ul class="menu-list"><li><a class="is-flex" href="#Cookie"><span class="mr-2">3.1</span><span>Cookie</span></a></li><li><a class="is-flex" href="#代理操作"><span class="mr-2">3.2</span><span>代理操作</span></a></li><li><a class="is-flex" href="#验证码的识别"><span class="mr-2">3.3</span><span>验证码的识别</span></a></li><li><a class="is-flex" href="#模拟登录-1"><span class="mr-2">3.4</span><span>模拟登录</span></a></li></ul></li><li><a class="is-flex" href="#selenium"><span class="mr-2">4</span><span>selenium</span></a><ul class="menu-list"><li><a class="is-flex" href="#selenium基础"><span class="mr-2">4.1</span><span>selenium基础</span></a></li><li><a class="is-flex" href="#动作链ActionChains"><span class="mr-2">4.2</span><span>动作链ActionChains</span></a></li><li><a class="is-flex" href="#12306模拟登录"><span class="mr-2">4.3</span><span>12306模拟登录</span></a></li><li><a class="is-flex" href="#余票监测"><span class="mr-2">4.4</span><span>余票监测</span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">五月 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">四月 2020</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/R%E8%AF%AD%E8%A8%80/"><span class="tag">R语言</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%99%E7%A8%8B/"><span class="tag">教程</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%88%AC%E8%99%AB/"><span class="tag">爬虫</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%83%E4%B9%A0%E9%A1%B9%E7%9B%AE/"><span class="tag">练习项目</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag is-grey-lightest">2</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">教程</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">笔记</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%BB%83%E4%B9%A0%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">练习项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><a class="media-left" href="/2020/05/18/%E6%B2%89%E8%BF%B7%E6%B8%B8%E6%88%8F/"><p class="image is-64x64"><img class="thumbnail" src="https://images.pexels.com/photos/194511/pexels-photo-194511.jpeg?cs=srgb&amp;dl=pexels-194511.jpg&amp;fm=jpg" alt="沉迷游戏"></p></a><div class="media-content size-small"><p><time dateTime="2020-05-18T07:01:16.000Z">2020-05-18</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/18/%E6%B2%89%E8%BF%B7%E6%B8%B8%E6%88%8F/">沉迷游戏</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><a class="media-left" href="/2020/05/14/%E7%9B%B2%E7%9B%AE%E6%B6%88%E8%B4%B9/"><p class="image is-64x64"><img class="thumbnail" src="https://images.pexels.com/photos/187041/pexels-photo-187041.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=750&amp;w=1260" alt="盲目消费"></p></a><div class="media-content size-small"><p><time dateTime="2020-05-14T12:11:39.000Z">2020-05-14</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/14/%E7%9B%B2%E7%9B%AE%E6%B6%88%E8%B4%B9/">盲目消费</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-13T05:50:50.000Z">2020-05-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/13/R%E8%AF%AD%E8%A8%80%E5%8F%AF%E8%A7%86%E5%8C%96%E7%AC%94%E8%AE%B0/">R语言可视化笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-08T06:57:37.000Z">2020-05-08</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/08/R%E8%AF%AD%E8%A8%80%E6%95%B0%E6%8D%AE%E6%93%8D%E7%BA%B5%E7%AC%94%E8%AE%B0/">R语言数据操纵笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-05-07T11:12:58.000Z">2020-05-07</time></p><p class="title is-6"><a class="link-muted" href="/2020/05/07/R%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B0/">R语言笔记</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="CZH&#039;s BLOG" height="28"></a><p class="size-small"><span>&copy; 2021 CZH</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub地址" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>